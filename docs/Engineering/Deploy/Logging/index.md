# æ—¥å¿—ç®¡ç†ä¸ç›‘æ§

## ç®€ä»‹

æ—¥å¿—ç®¡ç†æ˜¯ç°ä»£åº”ç”¨ç¨‹åºè¿ç»´çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå®ƒå¸®åŠ©å¼€å‘è€…å’Œè¿ç»´äººå‘˜ç›‘æ§åº”ç”¨çŠ¶æ€ã€è¯Šæ–­é—®é¢˜ã€åˆ†ææ€§èƒ½å’Œç¡®ä¿ç³»ç»Ÿå®‰å…¨ã€‚

### æ ¸å¿ƒä»·å€¼
- **é—®é¢˜è¯Šæ–­**ï¼šå¿«é€Ÿå®šä½å’Œè§£å†³ç³»ç»Ÿé—®é¢˜
- **æ€§èƒ½ç›‘æ§**ï¼šåˆ†æåº”ç”¨æ€§èƒ½ç“¶é¢ˆ
- **å®‰å…¨å®¡è®¡**ï¼šè¿½è¸ªå®‰å…¨äº‹ä»¶å’Œå¼‚å¸¸è¡Œä¸º
- **ä¸šåŠ¡åˆ†æ**ï¼šäº†è§£ç”¨æˆ·è¡Œä¸ºå’Œä¸šåŠ¡è¶‹åŠ¿
- **åˆè§„è¦æ±‚**ï¼šæ»¡è¶³æ³•è§„å’Œå®¡è®¡è¦æ±‚

### æ—¥å¿—ç±»å‹
- **åº”ç”¨æ—¥å¿—**ï¼šä¸šåŠ¡é€»è¾‘ã€é”™è¯¯ä¿¡æ¯ã€è°ƒè¯•ä¿¡æ¯
- **è®¿é—®æ—¥å¿—**ï¼šHTTP è¯·æ±‚ã€å“åº”æ—¶é—´ã€çŠ¶æ€ç 
- **ç³»ç»Ÿæ—¥å¿—**ï¼šæ“ä½œç³»ç»Ÿã€æœåŠ¡å™¨ã€ç½‘ç»œäº‹ä»¶
- **å®‰å…¨æ—¥å¿—**ï¼šè®¤è¯ã€æˆæƒã€å®‰å…¨äº‹ä»¶
- **å®¡è®¡æ—¥å¿—**ï¼šæ•°æ®å˜æ›´ã€ç”¨æˆ·æ“ä½œè®°å½•

## æ—¥å¿—çº§åˆ«ä¸æ ¼å¼

### æ ‡å‡†æ—¥å¿—çº§åˆ«

```javascript
// æ—¥å¿—çº§åˆ«å®šä¹‰
const LOG_LEVELS = {
  FATAL: 0,   // è‡´å‘½é”™è¯¯ï¼Œåº”ç”¨æ— æ³•ç»§ç»­è¿è¡Œ
  ERROR: 1,   // é”™è¯¯ä¿¡æ¯ï¼ŒåŠŸèƒ½å¼‚å¸¸ä½†åº”ç”¨å¯ç»§ç»­
  WARN: 2,    // è­¦å‘Šä¿¡æ¯ï¼Œæ½œåœ¨é—®é¢˜
  INFO: 3,    // ä¸€èˆ¬ä¿¡æ¯ï¼Œé‡è¦ä¸šåŠ¡æµç¨‹
  DEBUG: 4,   // è°ƒè¯•ä¿¡æ¯ï¼Œè¯¦ç»†æ‰§è¡Œè¿‡ç¨‹
  TRACE: 5    // è·Ÿè¸ªä¿¡æ¯ï¼Œæœ€è¯¦ç»†çš„æ‰§è¡Œä¿¡æ¯
}

// ä½¿ç”¨ç¤ºä¾‹
logger.info('ç”¨æˆ·ç™»å½•æˆåŠŸ', { userId: 12345, ip: '192.168.1.1' })
logger.error('æ•°æ®åº“è¿æ¥å¤±è´¥', { error: err.message, stack: err.stack })
logger.warn('API å“åº”æ—¶é—´è¿‡é•¿', { endpoint: '/api/users', duration: 2500 })
```

### ç»“æ„åŒ–æ—¥å¿—æ ¼å¼

```json
{
  "timestamp": "2024-01-15T10:30:00.000Z",
  "level": "INFO",
  "service": "user-service",
  "version": "1.2.3",
  "environment": "production",
  "requestId": "req-123456789",
  "userId": "user-12345",
  "message": "ç”¨æˆ·ç™»å½•æˆåŠŸ",
  "data": {
    "email": "user@example.com",
    "ip": "192.168.1.1",
    "userAgent": "Mozilla/5.0..."
  },
  "duration": 150,
  "tags": ["authentication", "success"]
}
```

## Node.js æ—¥å¿—å®ç°

### Winston æ—¥å¿—åº“

```javascript
// logger.js
const winston = require('winston')
const path = require('path')

// è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼
const logFormat = winston.format.combine(
  winston.format.timestamp({
    format: 'YYYY-MM-DD HH:mm:ss.SSS'
  }),
  winston.format.errors({ stack: true }),
  winston.format.json(),
  winston.format.prettyPrint()
)

// åˆ›å»º logger å®ä¾‹
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: logFormat,
  defaultMeta: {
    service: process.env.SERVICE_NAME || 'app',
    version: process.env.APP_VERSION || '1.0.0',
    environment: process.env.NODE_ENV || 'development'
  },
  transports: [
    // æ§åˆ¶å°è¾“å‡º
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      )
    }),
    
    // æ–‡ä»¶è¾“å‡º - é”™è¯¯æ—¥å¿—
    new winston.transports.File({
      filename: path.join('logs', 'error.log'),
      level: 'error',
      maxsize: 10 * 1024 * 1024, // 10MB
      maxFiles: 5,
      tailable: true
    }),
    
    // æ–‡ä»¶è¾“å‡º - æ‰€æœ‰æ—¥å¿—
    new winston.transports.File({
      filename: path.join('logs', 'combined.log'),
      maxsize: 10 * 1024 * 1024, // 10MB
      maxFiles: 10,
      tailable: true
    })
  ],
  
  // å¼‚å¸¸å¤„ç†
  exceptionHandlers: [
    new winston.transports.File({
      filename: path.join('logs', 'exceptions.log')
    })
  ],
  
  // æ‹’ç»å¤„ç†
  rejectionHandlers: [
    new winston.transports.File({
      filename: path.join('logs', 'rejections.log')
    })
  ]
})

// ç”Ÿäº§ç¯å¢ƒé…ç½®
if (process.env.NODE_ENV === 'production') {
  // ç§»é™¤æ§åˆ¶å°è¾“å‡º
  logger.remove(winston.transports.Console)
  
  // æ·»åŠ è¿œç¨‹æ—¥å¿—ä¼ è¾“
  logger.add(new winston.transports.Http({
    host: 'log-server.example.com',
    port: 80,
    path: '/logs'
  }))
}

module.exports = logger
```

### è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶

```javascript
// middleware/requestLogger.js
const logger = require('../utils/logger')
const { v4: uuidv4 } = require('uuid')

const requestLogger = (req, res, next) => {
  const startTime = Date.now()
  const requestId = uuidv4()
  
  // æ·»åŠ è¯·æ±‚ ID åˆ°è¯·æ±‚å¯¹è±¡
  req.requestId = requestId
  
  // è®°å½•è¯·æ±‚å¼€å§‹
  logger.info('è¯·æ±‚å¼€å§‹', {
    requestId,
    method: req.method,
    url: req.url,
    userAgent: req.get('User-Agent'),
    ip: req.ip || req.connection.remoteAddress,
    headers: req.headers
  })
  
  // ç›‘å¬å“åº”ç»“æŸ
  res.on('finish', () => {
    const duration = Date.now() - startTime
    const logLevel = res.statusCode >= 400 ? 'error' : 'info'
    
    logger[logLevel]('è¯·æ±‚å®Œæˆ', {
      requestId,
      method: req.method,
      url: req.url,
      statusCode: res.statusCode,
      duration,
      contentLength: res.get('Content-Length')
    })
  })
  
  next()
}

module.exports = requestLogger
```

### é”™è¯¯æ—¥å¿—å¤„ç†

```javascript
// middleware/errorLogger.js
const logger = require('../utils/logger')

const errorLogger = (err, req, res, next) => {
  // è®°å½•é”™è¯¯è¯¦æƒ…
  logger.error('åº”ç”¨é”™è¯¯', {
    requestId: req.requestId,
    error: {
      name: err.name,
      message: err.message,
      stack: err.stack
    },
    request: {
      method: req.method,
      url: req.url,
      headers: req.headers,
      body: req.body,
      params: req.params,
      query: req.query
    },
    user: req.user ? {
      id: req.user.id,
      email: req.user.email
    } : null
  })
  
  next(err)
}

module.exports = errorLogger
```

## å‰ç«¯æ—¥å¿—å®ç°

### æµè§ˆå™¨æ—¥å¿—æ”¶é›†

```javascript
// frontend/logger.js
class FrontendLogger {
  constructor(options = {}) {
    this.endpoint = options.endpoint || '/api/logs'
    this.batchSize = options.batchSize || 10
    this.flushInterval = options.flushInterval || 5000
    this.logBuffer = []
    this.sessionId = this.generateSessionId()
    
    this.startAutoFlush()
    this.setupErrorHandlers()
    this.setupPerformanceMonitoring()
  }
  
  generateSessionId() {
    return 'session-' + Date.now() + '-' + Math.random().toString(36).substr(2, 9)
  }
  
  log(level, message, data = {}) {
    const logEntry = {
      timestamp: new Date().toISOString(),
      level,
      message,
      data,
      sessionId: this.sessionId,
      url: window.location.href,
      userAgent: navigator.userAgent,
      userId: this.getUserId()
    }
    
    this.logBuffer.push(logEntry)
    
    // ç«‹å³å‘é€é”™è¯¯æ—¥å¿—
    if (level === 'ERROR' || level === 'FATAL') {
      this.flush()
    }
    
    // ç¼“å†²åŒºæ»¡æ—¶å‘é€
    if (this.logBuffer.length >= this.batchSize) {
      this.flush()
    }
  }
  
  info(message, data) {
    this.log('INFO', message, data)
  }
  
  warn(message, data) {
    this.log('WARN', message, data)
  }
  
  error(message, data) {
    this.log('ERROR', message, data)
  }
  
  debug(message, data) {
    if (process.env.NODE_ENV === 'development') {
      this.log('DEBUG', message, data)
    }
  }
  
  // å‘é€æ—¥å¿—åˆ°æœåŠ¡å™¨
  async flush() {
    if (this.logBuffer.length === 0) return
    
    const logs = [...this.logBuffer]
    this.logBuffer = []
    
    try {
      await fetch(this.endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({ logs })
      })
    } catch (error) {
      // å‘é€å¤±è´¥æ—¶é‡æ–°åŠ å…¥ç¼“å†²åŒº
      this.logBuffer.unshift(...logs)
      console.error('æ—¥å¿—å‘é€å¤±è´¥:', error)
    }
  }
  
  // è‡ªåŠ¨å®šæ—¶å‘é€
  startAutoFlush() {
    setInterval(() => {
      this.flush()
    }, this.flushInterval)
    
    // é¡µé¢å¸è½½æ—¶å‘é€å‰©ä½™æ—¥å¿—
    window.addEventListener('beforeunload', () => {
      if (this.logBuffer.length > 0) {
        navigator.sendBeacon(
          this.endpoint,
          JSON.stringify({ logs: this.logBuffer })
        )
      }
    })
  }
  
  // è®¾ç½®å…¨å±€é”™è¯¯å¤„ç†
  setupErrorHandlers() {
    // JavaScript é”™è¯¯
    window.addEventListener('error', (event) => {
      this.error('JavaScript é”™è¯¯', {
        message: event.message,
        filename: event.filename,
        lineno: event.lineno,
        colno: event.colno,
        stack: event.error?.stack
      })
    })
    
    // Promise æ‹’ç»
    window.addEventListener('unhandledrejection', (event) => {
      this.error('æœªå¤„ç†çš„ Promise æ‹’ç»', {
        reason: event.reason,
        stack: event.reason?.stack
      })
    })
    
    // èµ„æºåŠ è½½é”™è¯¯
    window.addEventListener('error', (event) => {
      if (event.target !== window) {
        this.error('èµ„æºåŠ è½½é”™è¯¯', {
          tagName: event.target.tagName,
          src: event.target.src || event.target.href,
          message: 'èµ„æºåŠ è½½å¤±è´¥'
        })
      }
    }, true)
  }
  
  // æ€§èƒ½ç›‘æ§
  setupPerformanceMonitoring() {
    // é¡µé¢åŠ è½½æ€§èƒ½
    window.addEventListener('load', () => {
      setTimeout(() => {
        const perfData = performance.getEntriesByType('navigation')[0]
        
        this.info('é¡µé¢åŠ è½½æ€§èƒ½', {
          loadTime: perfData.loadEventEnd - perfData.loadEventStart,
          domContentLoaded: perfData.domContentLoadedEventEnd - perfData.domContentLoadedEventStart,
          firstPaint: this.getFirstPaint(),
          firstContentfulPaint: this.getFirstContentfulPaint()
        })
      }, 0)
    })
    
    // ç”¨æˆ·äº¤äº’ç›‘æ§
    this.setupUserInteractionLogging()
  }
  
  getFirstPaint() {
    const paintEntries = performance.getEntriesByType('paint')
    const firstPaint = paintEntries.find(entry => entry.name === 'first-paint')
    return firstPaint ? firstPaint.startTime : null
  }
  
  getFirstContentfulPaint() {
    const paintEntries = performance.getEntriesByType('paint')
    const fcp = paintEntries.find(entry => entry.name === 'first-contentful-paint')
    return fcp ? fcp.startTime : null
  }
  
  setupUserInteractionLogging() {
    // ç‚¹å‡»äº‹ä»¶
    document.addEventListener('click', (event) => {
      this.debug('ç”¨æˆ·ç‚¹å‡»', {
        tagName: event.target.tagName,
        className: event.target.className,
        id: event.target.id,
        text: event.target.textContent?.substring(0, 50)
      })
    })
    
    // é¡µé¢å¯è§æ€§å˜åŒ–
    document.addEventListener('visibilitychange', () => {
      this.info('é¡µé¢å¯è§æ€§å˜åŒ–', {
        hidden: document.hidden,
        visibilityState: document.visibilityState
      })
    })
  }
  
  getUserId() {
    // ä»æœ¬åœ°å­˜å‚¨æˆ–å…¨å±€å˜é‡è·å–ç”¨æˆ· ID
    return window.currentUser?.id || localStorage.getItem('userId') || 'anonymous'
  }
}

// åˆ›å»ºå…¨å±€æ—¥å¿—å®ä¾‹
const logger = new FrontendLogger({
  endpoint: '/api/frontend-logs',
  batchSize: 5,
  flushInterval: 3000
})

// å¯¼å‡ºæ—¥å¿—æ–¹æ³•
window.logger = logger
export default logger
```

## ELK Stack æ—¥å¿—ç³»ç»Ÿ

### Elasticsearch é…ç½®

```yaml
# docker-compose.yml
version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - elk

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    ports:
      - "5044:5044"
      - "9600:9600"
    volumes:
      - ./logstash/config:/usr/share/logstash/pipeline
    networks:
      - elk
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - elk
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: filebeat
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./logs:/app/logs:ro
    networks:
      - elk
    depends_on:
      - elasticsearch
      - logstash

volumes:
  elasticsearch_data:

networks:
  elk:
    driver: bridge
```

### Logstash é…ç½®

```ruby
# logstash/config/logstash.conf
input {
  beats {
    port => 5044
  }
  
  http {
    port => 8080
    codec => json
  }
}

filter {
  # è§£æ JSON æ—¥å¿—
  if [fields][log_type] == "application" {
    json {
      source => "message"
    }
    
    # è§£ææ—¶é—´æˆ³
    date {
      match => [ "timestamp", "ISO8601" ]
    }
    
    # æ·»åŠ åœ°ç†ä½ç½®ä¿¡æ¯
    if [data][ip] {
      geoip {
        source => "[data][ip]"
        target => "geoip"
      }
    }
    
    # è§£æç”¨æˆ·ä»£ç†
    if [data][userAgent] {
      useragent {
        source => "[data][userAgent]"
        target => "user_agent"
      }
    }
  }
  
  # è§£æ Nginx è®¿é—®æ—¥å¿—
  if [fields][log_type] == "nginx" {
    grok {
      match => { 
        "message" => "%{NGINXACCESS}"
      }
    }
    
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
    
    mutate {
      convert => { "response" => "integer" }
      convert => { "bytes" => "integer" }
      convert => { "responsetime" => "float" }
    }
  }
  
  # æ·»åŠ ç¯å¢ƒæ ‡ç­¾
  mutate {
    add_field => { "environment" => "%{[fields][environment]}" }
    add_field => { "service" => "%{[fields][service]}" }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{[fields][log_type]}-%{+YYYY.MM.dd}"
  }
  
  # è°ƒè¯•è¾“å‡º
  stdout {
    codec => rubydebug
  }
}
```

### Filebeat é…ç½®

```yaml
# filebeat/filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /app/logs/*.log
  fields:
    log_type: application
    service: node-app
    environment: production
  fields_under_root: false
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after

- type: docker
  enabled: true
  containers.ids:
    - '*'
  fields:
    log_type: docker
  fields_under_root: false

processors:
- add_host_metadata:
    when.not.contains.tags: forwarded
- add_docker_metadata: ~

output.logstash:
  hosts: ["logstash:5044"]

logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

## æ—¥å¿—åˆ†æä¸ç›‘æ§

### Kibana ä»ªè¡¨æ¿é…ç½®

```json
{
  "version": "8.11.0",
  "objects": [
    {
      "id": "app-logs-dashboard",
      "type": "dashboard",
      "attributes": {
        "title": "åº”ç”¨æ—¥å¿—ç›‘æ§",
        "description": "åº”ç”¨ç¨‹åºæ—¥å¿—åˆ†æä»ªè¡¨æ¿",
        "panelsJSON": "[\n  {\n    \"id\": \"log-level-pie\",\n    \"type\": \"visualization\",\n    \"gridData\": {\n      \"x\": 0,\n      \"y\": 0,\n      \"w\": 24,\n      \"h\": 15\n    }\n  },\n  {\n    \"id\": \"error-timeline\",\n    \"type\": \"visualization\",\n    \"gridData\": {\n      \"x\": 24,\n      \"y\": 0,\n      \"w\": 24,\n      \"h\": 15\n    }\n  }\n]"
      }
    }
  ]
}
```

### æ—¥å¿—å‘Šè­¦é…ç½®

```javascript
// alerting/logAlerts.js
const { Client } = require('@elastic/elasticsearch')
const nodemailer = require('nodemailer')

class LogAlerting {
  constructor() {
    this.esClient = new Client({ node: 'http://localhost:9200' })
    this.emailTransporter = nodemailer.createTransporter({
      host: 'smtp.example.com',
      port: 587,
      secure: false,
      auth: {
        user: process.env.SMTP_USER,
        pass: process.env.SMTP_PASS
      }
    })
    
    this.alertRules = [
      {
        name: 'é”™è¯¯ç‡è¿‡é«˜',
        query: {
          bool: {
            must: [
              { term: { level: 'ERROR' } },
              { range: { '@timestamp': { gte: 'now-5m' } } }
            ]
          }
        },
        threshold: 10,
        interval: 300000 // 5åˆ†é’Ÿ
      },
      {
        name: 'å“åº”æ—¶é—´è¿‡é•¿',
        query: {
          bool: {
            must: [
              { range: { duration: { gte: 5000 } } },
              { range: { '@timestamp': { gte: 'now-10m' } } }
            ]
          }
        },
        threshold: 5,
        interval: 600000 // 10åˆ†é’Ÿ
      }
    ]
  }
  
  async startMonitoring() {
    this.alertRules.forEach(rule => {
      setInterval(async () => {
        await this.checkRule(rule)
      }, rule.interval)
    })
  }
  
  async checkRule(rule) {
    try {
      const response = await this.esClient.count({
        index: 'logs-*',
        body: {
          query: rule.query
        }
      })
      
      if (response.body.count >= rule.threshold) {
        await this.sendAlert(rule, response.body.count)
      }
    } catch (error) {
      console.error('å‘Šè­¦æ£€æŸ¥å¤±è´¥:', error)
    }
  }
  
  async sendAlert(rule, count) {
    const alertMessage = {
      from: 'alerts@example.com',
      to: 'admin@example.com',
      subject: `ğŸš¨ æ—¥å¿—å‘Šè­¦: ${rule.name}`,
      html: `
        <h2>æ—¥å¿—å‘Šè­¦é€šçŸ¥</h2>
        <p><strong>è§„åˆ™:</strong> ${rule.name}</p>
        <p><strong>è§¦å‘æ¬¡æ•°:</strong> ${count}</p>
        <p><strong>é˜ˆå€¼:</strong> ${rule.threshold}</p>
        <p><strong>æ—¶é—´:</strong> ${new Date().toISOString()}</p>
        <p><a href="http://localhost:5601">æŸ¥çœ‹ Kibana ä»ªè¡¨æ¿</a></p>
      `
    }
    
    try {
      await this.emailTransporter.sendMail(alertMessage)
      console.log(`å‘Šè­¦é‚®ä»¶å·²å‘é€: ${rule.name}`)
    } catch (error) {
      console.error('å‘Šè­¦é‚®ä»¶å‘é€å¤±è´¥:', error)
    }
  }
}

// å¯åŠ¨å‘Šè­¦ç›‘æ§
const alerting = new LogAlerting()
alerting.startMonitoring()

module.exports = LogAlerting
```

## æ—¥å¿—æœ€ä½³å®è·µ

### æ—¥å¿—è®¾è®¡åŸåˆ™

```javascript
// æœ€ä½³å®è·µç¤ºä¾‹
class BestPracticeLogger {
  constructor() {
    this.logger = require('./logger')
  }
  
  // âœ… å¥½çš„æ—¥å¿—å®è·µ
  logUserAction(action, userId, details = {}) {
    this.logger.info('ç”¨æˆ·æ“ä½œ', {
      action,
      userId,
      timestamp: new Date().toISOString(),
      ...details,
      // æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
      sessionId: this.getSessionId(),
      requestId: this.getRequestId(),
      userAgent: this.getUserAgent()
    })
  }
  
  // âœ… ç»“æ„åŒ–é”™è¯¯æ—¥å¿—
  logError(error, context = {}) {
    this.logger.error('åº”ç”¨é”™è¯¯', {
      error: {
        name: error.name,
        message: error.message,
        stack: error.stack,
        code: error.code
      },
      context,
      timestamp: new Date().toISOString(),
      severity: this.calculateSeverity(error)
    })
  }
  
  // âœ… æ€§èƒ½æ—¥å¿—
  logPerformance(operation, duration, metadata = {}) {
    const level = duration > 1000 ? 'warn' : 'info'
    
    this.logger[level]('æ€§èƒ½æŒ‡æ ‡', {
      operation,
      duration,
      metadata,
      timestamp: new Date().toISOString(),
      performanceGrade: this.getPerformanceGrade(duration)
    })
  }
  
  // âœ… ä¸šåŠ¡äº‹ä»¶æ—¥å¿—
  logBusinessEvent(event, data = {}) {
    this.logger.info('ä¸šåŠ¡äº‹ä»¶', {
      event,
      data,
      timestamp: new Date().toISOString(),
      category: 'business',
      importance: this.getEventImportance(event)
    })
  }
  
  calculateSeverity(error) {
    if (error.name === 'ValidationError') return 'low'
    if (error.name === 'DatabaseError') return 'high'
    if (error.name === 'SecurityError') return 'critical'
    return 'medium'
  }
  
  getPerformanceGrade(duration) {
    if (duration < 100) return 'excellent'
    if (duration < 500) return 'good'
    if (duration < 1000) return 'fair'
    return 'poor'
  }
  
  getEventImportance(event) {
    const criticalEvents = ['user_registration', 'payment_completed', 'security_breach']
    return criticalEvents.includes(event) ? 'critical' : 'normal'
  }
}

// âŒ é¿å…çš„æ—¥å¿—åæ¨¡å¼
class BadLoggingExamples {
  badExamples() {
    // âŒ æ—¥å¿—ä¿¡æ¯ä¸å¤Ÿè¯¦ç»†
    logger.info('ç”¨æˆ·ç™»å½•')
    
    // âŒ æ•æ„Ÿä¿¡æ¯æ³„éœ²
    logger.info('ç”¨æˆ·ç™»å½•', { password: 'secret123' })
    
    // âŒ æ—¥å¿—çº§åˆ«ä½¿ç”¨é”™è¯¯
    logger.error('ç”¨æˆ·ç‚¹å‡»æŒ‰é’®')
    
    // âŒ å­—ç¬¦ä¸²æ‹¼æ¥è€Œéç»“æ„åŒ–
    logger.info(`ç”¨æˆ· ${userId} åœ¨ ${new Date()} æ‰§è¡Œäº† ${action}`)
    
    // âŒ è¿‡åº¦æ—¥å¿—è®°å½•
    for (let i = 0; i < 1000000; i++) {
      logger.debug(`å¤„ç†ç¬¬ ${i} æ¡è®°å½•`)
    }
  }
}
```

### æ—¥å¿—å®‰å…¨ä¸åˆè§„

```javascript
// security/logSecurity.js
class LogSecurity {
  constructor() {
    this.sensitiveFields = [
      'password', 'token', 'secret', 'key', 'auth',
      'ssn', 'credit_card', 'phone', 'email'
    ]
  }
  
  // æ•°æ®è„±æ•
  sanitizeLogData(data) {
    if (typeof data !== 'object' || data === null) {
      return data
    }
    
    const sanitized = { ...data }
    
    Object.keys(sanitized).forEach(key => {
      if (this.isSensitiveField(key)) {
        sanitized[key] = this.maskSensitiveData(sanitized[key])
      } else if (typeof sanitized[key] === 'object') {
        sanitized[key] = this.sanitizeLogData(sanitized[key])
      }
    })
    
    return sanitized
  }
  
  isSensitiveField(fieldName) {
    const lowerField = fieldName.toLowerCase()
    return this.sensitiveFields.some(sensitive => 
      lowerField.includes(sensitive)
    )
  }
  
  maskSensitiveData(value) {
    if (typeof value !== 'string') {
      return '[REDACTED]'
    }
    
    if (value.length <= 4) {
      return '*'.repeat(value.length)
    }
    
    return value.substring(0, 2) + '*'.repeat(value.length - 4) + value.substring(value.length - 2)
  }
  
  // GDPR åˆè§„ - ç”¨æˆ·æ•°æ®åˆ é™¤
  async deleteUserLogs(userId) {
    try {
      // ä» Elasticsearch åˆ é™¤ç”¨æˆ·ç›¸å…³æ—¥å¿—
      await this.esClient.deleteByQuery({
        index: 'logs-*',
        body: {
          query: {
            term: { userId }
          }
        }
      })
      
      // ä»æ–‡ä»¶ç³»ç»Ÿåˆ é™¤
      await this.deleteUserLogsFromFiles(userId)
      
      console.log(`ç”¨æˆ· ${userId} çš„æ—¥å¿—å·²åˆ é™¤`)
    } catch (error) {
      console.error('åˆ é™¤ç”¨æˆ·æ—¥å¿—å¤±è´¥:', error)
    }
  }
  
  // æ—¥å¿—åŠ å¯†
  encryptLogEntry(logEntry) {
    const crypto = require('crypto')
    const algorithm = 'aes-256-gcm'
    const key = Buffer.from(process.env.LOG_ENCRYPTION_KEY, 'hex')
    const iv = crypto.randomBytes(16)
    
    const cipher = crypto.createCipher(algorithm, key, iv)
    
    let encrypted = cipher.update(JSON.stringify(logEntry), 'utf8', 'hex')
    encrypted += cipher.final('hex')
    
    const authTag = cipher.getAuthTag()
    
    return {
      encrypted,
      iv: iv.toString('hex'),
      authTag: authTag.toString('hex')
    }
  }
}

module.exports = LogSecurity
```

## æ€§èƒ½ä¼˜åŒ–

### å¼‚æ­¥æ—¥å¿—å¤„ç†

```javascript
// performance/asyncLogger.js
const { Worker, isMainThread, parentPort, workerData } = require('worker_threads')
const fs = require('fs').promises
const path = require('path')

class AsyncLogger {
  constructor(options = {}) {
    this.bufferSize = options.bufferSize || 1000
    this.flushInterval = options.flushInterval || 5000
    this.logBuffer = []
    this.worker = null
    
    this.initWorker()
    this.startPeriodicFlush()
  }
  
  initWorker() {
    if (isMainThread) {
      this.worker = new Worker(__filename, {
        workerData: {
          logDir: path.join(process.cwd(), 'logs')
        }
      })
      
      this.worker.on('error', (error) => {
        console.error('æ—¥å¿—å·¥ä½œçº¿ç¨‹é”™è¯¯:', error)
      })
    }
  }
  
  log(entry) {
    this.logBuffer.push({
      ...entry,
      timestamp: new Date().toISOString()
    })
    
    if (this.logBuffer.length >= this.bufferSize) {
      this.flush()
    }
  }
  
  flush() {
    if (this.logBuffer.length === 0) return
    
    const logs = [...this.logBuffer]
    this.logBuffer = []
    
    if (this.worker) {
      this.worker.postMessage({ type: 'WRITE_LOGS', logs })
    }
  }
  
  startPeriodicFlush() {
    setInterval(() => {
      this.flush()
    }, this.flushInterval)
    
    // è¿›ç¨‹é€€å‡ºæ—¶åˆ·æ–°ç¼“å†²åŒº
    process.on('exit', () => this.flush())
    process.on('SIGINT', () => {
      this.flush()
      process.exit(0)
    })
  }
}

// Worker çº¿ç¨‹å¤„ç†æ—¥å¿—å†™å…¥
if (!isMainThread) {
  const logDir = workerData.logDir
  
  parentPort.on('message', async ({ type, logs }) => {
    if (type === 'WRITE_LOGS') {
      await writeLogs(logs)
    }
  })
  
  async function writeLogs(logs) {
    try {
      // æŒ‰æ—¥æœŸå’Œçº§åˆ«åˆ†ç»„
      const groupedLogs = groupLogsByDateAndLevel(logs)
      
      // å¹¶è¡Œå†™å…¥ä¸åŒæ–‡ä»¶
      const writePromises = Object.entries(groupedLogs).map(
        ([filename, logEntries]) => writeLogFile(filename, logEntries)
      )
      
      await Promise.all(writePromises)
    } catch (error) {
      console.error('å†™å…¥æ—¥å¿—å¤±è´¥:', error)
    }
  }
  
  function groupLogsByDateAndLevel(logs) {
    const groups = {}
    
    logs.forEach(log => {
      const date = new Date(log.timestamp).toISOString().split('T')[0]
      const filename = `${date}-${log.level.toLowerCase()}.log`
      
      if (!groups[filename]) {
        groups[filename] = []
      }
      
      groups[filename].push(log)
    })
    
    return groups
  }
  
  async function writeLogFile(filename, logs) {
    const filepath = path.join(logDir, filename)
    const logLines = logs.map(log => JSON.stringify(log)).join('\n') + '\n'
    
    await fs.appendFile(filepath, logLines, 'utf8')
  }
}

module.exports = AsyncLogger
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è§£å†³

```bash
# æ—¥å¿—æ–‡ä»¶è¿‡å¤§é—®é¢˜
# ä½¿ç”¨ logrotate è‡ªåŠ¨è½®è½¬
sudo nano /etc/logrotate.d/myapp

# logrotate é…ç½®
/var/log/myapp/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 0644 www-data www-data
    postrotate
        systemctl reload myapp
    endscript
}

# æ‰‹åŠ¨æµ‹è¯• logrotate
sudo logrotate -d /etc/logrotate.d/myapp
sudo logrotate -f /etc/logrotate.d/myapp

# æ—¥å¿—æƒé™é—®é¢˜
sudo chown -R www-data:www-data /var/log/myapp
sudo chmod -R 644 /var/log/myapp

# Elasticsearch ç£ç›˜ç©ºé—´ä¸è¶³
# åˆ é™¤æ—§ç´¢å¼•
curl -X DELETE "localhost:9200/logs-*-2023.01.*"

# è®¾ç½®ç´¢å¼•ç”Ÿå‘½å‘¨æœŸç®¡ç†
curl -X PUT "localhost:9200/_ilm/policy/logs-policy" -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "1GB",
            "max_age": "7d"
          }
        }
      },
      "delete": {
        "min_age": "30d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}'

# æ—¥å¿—è§£æé”™è¯¯
# æ£€æŸ¥ Logstash é…ç½®
sudo docker logs logstash

# æµ‹è¯• Grok æ¨¡å¼
echo 'test log line' | sudo docker exec -i logstash /usr/share/logstash/bin/logstash -e 'input{stdin{}} filter{grok{match=>{"message"=>"%{WORD:word}"}}} output{stdout{codec=>rubydebug}}'
```

### ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# monitor-logs.sh

# æ—¥å¿—ç³»ç»Ÿå¥åº·æ£€æŸ¥è„šæœ¬

LOG_DIR="/var/log/myapp"
ELASTIC_URL="http://localhost:9200"
KIBANA_URL="http://localhost:5601"
ALERT_EMAIL="admin@example.com"

# æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å¤§å°
check_log_size() {
    echo "æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å¤§å°..."
    
    find $LOG_DIR -name "*.log" -size +100M | while read file; do
        echo "è­¦å‘Š: æ—¥å¿—æ–‡ä»¶è¿‡å¤§ - $file"
        # å‘é€å‘Šè­¦é‚®ä»¶
        echo "æ—¥å¿—æ–‡ä»¶ $file è¶…è¿‡ 100MB" | mail -s "æ—¥å¿—æ–‡ä»¶è¿‡å¤§å‘Šè­¦" $ALERT_EMAIL
    done
}

# æ£€æŸ¥ Elasticsearch çŠ¶æ€
check_elasticsearch() {
    echo "æ£€æŸ¥ Elasticsearch çŠ¶æ€..."
    
    response=$(curl -s -o /dev/null -w "%{http_code}" $ELASTIC_URL/_cluster/health)
    
    if [ $response -ne 200 ]; then
        echo "é”™è¯¯: Elasticsearch ä¸å¯ç”¨ (HTTP $response)"
        echo "Elasticsearch æœåŠ¡ä¸å¯ç”¨" | mail -s "Elasticsearch å‘Šè­¦" $ALERT_EMAIL
        return 1
    fi
    
    # æ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€
    health=$(curl -s $ELASTIC_URL/_cluster/health | jq -r '.status')
    
    if [ "$health" != "green" ]; then
        echo "è­¦å‘Š: Elasticsearch é›†ç¾¤çŠ¶æ€ä¸º $health"
        echo "Elasticsearch é›†ç¾¤çŠ¶æ€å¼‚å¸¸: $health" | mail -s "Elasticsearch å¥åº·å‘Šè­¦" $ALERT_EMAIL
    fi
}

# æ£€æŸ¥ Kibana çŠ¶æ€
check_kibana() {
    echo "æ£€æŸ¥ Kibana çŠ¶æ€..."
    
    response=$(curl -s -o /dev/null -w "%{http_code}" $KIBANA_URL/api/status)
    
    if [ $response -ne 200 ]; then
        echo "é”™è¯¯: Kibana ä¸å¯ç”¨ (HTTP $response)"
        echo "Kibana æœåŠ¡ä¸å¯ç”¨" | mail -s "Kibana å‘Šè­¦" $ALERT_EMAIL
    fi
}

# æ£€æŸ¥ç£ç›˜ç©ºé—´
check_disk_space() {
    echo "æ£€æŸ¥ç£ç›˜ç©ºé—´..."
    
    usage=$(df $LOG_DIR | awk 'NR==2 {print $5}' | sed 's/%//')
    
    if [ $usage -gt 80 ]; then
        echo "è­¦å‘Š: æ—¥å¿—ç›®å½•ç£ç›˜ä½¿ç”¨ç‡ ${usage}%"
        echo "æ—¥å¿—ç›®å½•ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: ${usage}%" | mail -s "ç£ç›˜ç©ºé—´å‘Šè­¦" $ALERT_EMAIL
    fi
}

# æ£€æŸ¥æ—¥å¿—é”™è¯¯ç‡
check_error_rate() {
    echo "æ£€æŸ¥æ—¥å¿—é”™è¯¯ç‡..."
    
    # æœ€è¿‘1å°æ—¶çš„é”™è¯¯æ—¥å¿—æ•°é‡
    error_count=$(curl -s "$ELASTIC_URL/logs-*/_count" -H 'Content-Type: application/json' -d'{
      "query": {
        "bool": {
          "must": [
            {"term": {"level": "ERROR"}},
            {"range": {"@timestamp": {"gte": "now-1h"}}}
          ]
        }
      }
    }' | jq '.count')
    
    if [ $error_count -gt 100 ]; then
        echo "è­¦å‘Š: æœ€è¿‘1å°æ—¶é”™è¯¯æ—¥å¿—æ•°é‡ $error_count"
        echo "é”™è¯¯æ—¥å¿—æ•°é‡å¼‚å¸¸: $error_count" | mail -s "é”™è¯¯ç‡å‘Šè­¦" $ALERT_EMAIL
    fi
}

# ä¸»å‡½æ•°
main() {
    echo "å¼€å§‹æ—¥å¿—ç³»ç»Ÿå¥åº·æ£€æŸ¥ - $(date)"
    
    check_log_size
    check_elasticsearch
    check_kibana
    check_disk_space
    check_error_rate
    
    echo "å¥åº·æ£€æŸ¥å®Œæˆ - $(date)"
}

# è¿è¡Œæ£€æŸ¥
main
```

## å‚è€ƒèµ„æº

### ğŸ“š å­¦ä¹ èµ„æº
- [Winston å®˜æ–¹æ–‡æ¡£](https://github.com/winstonjs/winston)
- [ELK Stack å®˜æ–¹æŒ‡å—](https://www.elastic.co/guide/)
- [æ—¥å¿—ç®¡ç†æœ€ä½³å®è·µ](https://www.loggly.com/ultimate-guide/)
- [ç»“æ„åŒ–æ—¥å¿—æŒ‡å—](https://stackify.com/what-is-structured-logging-and-why-developers-need-it/)

### ğŸ› ï¸ å·¥å…·æ¨è
- **æ—¥å¿—åº“**: Winston, Bunyan, Pino, Log4js
- **æ—¥å¿—æ”¶é›†**: Filebeat, Fluentd, Logstash
- **æ—¥å¿—å­˜å‚¨**: Elasticsearch, MongoDB, InfluxDB
- **æ—¥å¿—åˆ†æ**: Kibana, Grafana, Splunk
- **å‘Šè­¦å·¥å…·**: ElastAlert, Prometheus AlertManager

### ğŸ“– æœ€ä½³å®è·µæŒ‡å—
- [12-Factor App æ—¥å¿—åŸåˆ™](https://12factor.net/logs)
- [OWASP æ—¥å¿—å®‰å…¨æŒ‡å—](https://owasp.org/www-project-logging-guide/)
- [Google SRE æ—¥å¿—å®è·µ](https://sre.google/sre-book/monitoring-distributed-systems/)
- [å¾®æœåŠ¡æ—¥å¿—èšåˆæ¨¡å¼](https://microservices.io/patterns/observability/application-logging.html)

---

> ğŸ’¡ **æç¤º**ï¼šè‰¯å¥½çš„æ—¥å¿—ç®¡ç†æ˜¯ç³»ç»Ÿå¯è§‚æµ‹æ€§çš„åŸºç¡€ï¼Œåˆç†çš„æ—¥å¿—ç­–ç•¥èƒ½å¤Ÿå¤§å¤§æå‡é—®é¢˜è¯Šæ–­å’Œç³»ç»Ÿç›‘æ§çš„æ•ˆç‡ï¼